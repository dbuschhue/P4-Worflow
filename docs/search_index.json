[
["index.html", "Untitled 1 Vorwort: DISCLAIMER", " Untitled Tina Grottke, Philipp Möhrke, Marvin Rost, David Buschhüter (Hrsg.) 2020-10-01 1 Vorwort: DISCLAIMER ACHTUNG: DIES IST EIN ERSTER DRAFT. WIR ÜBERNEHMEN KEINE VERANTWORTUNG FÜR DIE RICHTIGKEIT DER INFORMATIONEN. ES IST ALS “WORK IN PROGRESS” ZU SEHEN. "],
["einführung.html", "2 Einführung 2.1 Rasch-Modellierung 2.2 Der Datensatz", " 2 Einführung 2.1 Rasch-Modellierung Bei vielen Test geht es um die Frage, ob ein Probant eine bestimmte Fähigkeit besitzt und damit eine Aufgabe richtig lösen kann. Diese Fähigkeit, die man messen möchte, ist aber meist nicht direkt zugänglich. Sie ist latent. Der Zugang zu dieser Fähigkeit kann also nur über Aufgaben oder Fragen erfolgen, die der Probant beantwortet und in deren Beantwortung sich die latente Fähigkeit zeigt. Die Wahrscheinlichkeit, dass ein Proband eine Aufgabe richtig lösen kann, hängt sowohl von dessen Fähigkeit als auch von der Schwierigkeit der Aufgabe ab. Eine Aufgabe, die sehr oft richtig gelöst wird, könnte z.B. sehr einfach sein. Die Probanden könnten aber auch alle eine sehr hohe Fähigkeit haben, die ihnen erlaubt, die Aufgabe erfolgreich zu bearbeiten. Beide Punkte sind also auf den ersten Blick nicht voneinander zu trennen. Die Rasch-Modellierung (benannt nach dem dänischen Statistiker Georg Rasch (1901–1980)) löst dieses Problem. Das Modell beschreibt wie wahrscheinlich es ist, dass ein Proband \\(n\\) ein Item \\(i\\) richtig löst in Abhängigkeit eines individuellen Personen- oder Personenfähigkeitsparameters \\(\\theta_n\\) für jeden Probanden, welcher das Fähigkeitsausmaß des Probanden \\(n\\) beschreibt und eines Aufgaben- oder Aufgabenschwierigkeitsparameters \\(\\delta_i\\), der ist den Schwierigkeitsgrad der Aufgabe \\(i\\) beschreibt. Man erhält also aus einem Datensatz von richtigen oder falschen Antworten (ordinale Daten) der Pronden zu verschiednen Aufgaben ein kontinuierliches metrisches Maß in Form der Personenfähigkeitsparameter \\(\\theta_n\\) und der Aufgabenschwierigkeitsparameter \\(\\delta_i\\). Prinzipiell ist dieses Modell nicht auf dichotom zu bewertenden Aufgaben beschränkt. Auch likert-skalierte Items sind z.B. möglich, sollen aber nicht Gegenstand dieses Buches sein. Die Modellannahmen lauten wie folgt: Das Maß der Fähigkeit jedes Probanden ist ausschließlich durch den Personenfähigkeitsparameter charakterisiert. Das heißt, dass es keine anderen Einflussfaktoren gibt und ein sog. eindimensionales Modell berechnet wird. Die Schwierigkeit der einzelnen Aufgaben ist ausschließlich durch den Aufgabenschwierigkeitsparameter charakterisiert. Die Schwierigkeit stellt also ebenfalls ein eindimensionales Merkmal dar. Beide Parameter werden auf der selben Skala gemessen. Die Leistungen eines Probanden hängt über alle Aufgaben hinweg – abgesehen von Zufall –, einzig von der Fähigkeit des Probanden und der Schwierigkeit der Aufgabe ab, nicht aber davon, welche anderen Aufgaben er oder sie bereits gelöst hat oder noch lösen wird. Zusammehhänge zwischen dem Fähigkeitsparameter und der Schwierigkeitsparameter der Aufgabe sind viele vorstellbar. Der Zusammehang sollte aber auf jeden Fall so sein, dass die Wahrscheinlichkeit einer richtigen Antwort mit wachsender Fähigkeit steigt. Bei einem perfekten Item und idealen Probanden würde man hoffen, dass die Wahrscheinlichkeit einer richtigen Antwort für Probanden mit einer niedrigen Fähigkeit bei null liegt und ab einer bestimmten Fähigkeit sprunghaft auf eins ansteigt. Ganz so ideal wird es nicht sein und der Übergangsbereich wird etwas weicher verlaufen. Explizit wird angenommen, dass sich die Wahrscheinlichkeit einer richtigen Antwort einer logistischen Funktion folgend entwickelt. Man setzt für die Wahrscheinlichkeit einer richtigen Antwort unter der Bedingung einer Personenfähigkeit \\(\\theta_n\\) und Schwierigkeit der Aufgabe \\(\\delta_i\\) an: \\[P(1|\\theta_n, \\delta_i) = \\frac{\\exp(\\theta_n - \\delta_i)}{1+\\exp(\\theta_n - \\delta_i)} \\] Für eine Aufgabe mit dem Schwierigkeitsparameter 0 erhält man so folgenden Verlauf der Lösungswahrscheinlichkeit über den Fähigkeitsparameter. Personen mit einem Fähigkeitsparameter von -5.0 lösen die Aufgabe also fast nie, während Personen mit einem Fähigkeitsparameter von +5.0 die Aufgabe fast immer lösen. Personen, deren Fähigkeitsparameter gerade so groß ist wie der Parameter der Aufgabenschwierigkeit lösen die Aufgabe in genau 50% der Fälle. Für zwei verschieden schwierige Items erhält man so zwei gegeneinander in x-Richtung verschobene Kurven mit. Dies ist im folgenden Plot Beispiel haft für eine Aufgabe mit einem Itemschwierigkeitsparameter von -0.5 (blau) und eine mit 1.7 (rot) gezeigt. Bei einer Personen mit einem Personenfähigkeitsparmeter von 0 würden also die erste Aufgabe (blau) in gut 60 % der Fälle lösen, während die zweite Aufgabe (rot) nur von ca. 15 % der Personen gelöst werden würde. Schau man sich Formel für die Lösungswahrscheinlichkeit noch einmal an, sieht man, dass die Lösungswahrscheinlichkeit für Aufgabe \\(i\\) einzig von der Differenz von den Parametern für Personenfähigkeit und Aufgabengabenschwierigkeit ab. Formt man die Gleichung etwas um, kann man auch schreiben \\[\\ln\\left(\\frac{P(1|\\theta_n, \\delta_i)}{1 - P(1|\\theta_n, \\delta_i)}\\right) = \\ln\\left(\\frac{P(1|\\theta_n, \\delta_i)}{ P(0|\\theta_n, \\delta_i)}\\right) = \\theta_n - \\delta_i\\] Der natürliche Logarithmus der Chance (Wahrscheinlichkeit der richtigen Lösung geteilt durch Wahrscheinlichkeit der falschen Lösung) gleich der Differenz von Personenfähigkeitsparameter und Aufgabengabenschwierigkeitsparameter. Plottet man die Chance gegen diese Differenz erhält man eine Gerade mit Steigung 1. Diese Steigung und damit die Steigung des Übergangs von \\(P\\) wird für das Rasch-Modell also als fest angenommen. Die Steigung wird auch als Trennschärfe bezeichnet, weil Sie eine Aussage darüber liefert, wie klar ein Item zwischen den Fähigkeiten zweier Probanden dicht an der Schwierigkeit des Items trennen kann. Idealisiert würde ein perfektes Item von einer Person mit einer Fähigkeit \\(\\theta_n\\) nie gelöst werden, während ein Person mit einer leicht höheren Fähigkeit das Item immer löst. Bei höheren Modellen wie dem 2-PL geht die Steigung als zusätzlicher Parameter ein. 2.1.1 Beispiel Stellt man sich für ein Beispiel vor, dass die Kochkompetenz von Probanden gemessen werden soll. Dies stellt eine latente Fähigkeit dar, die nur über Testaufgaben auf diesem Gebiet erforscht werden kann. Ein entsprechender Test sollte aus verschiedenen schweren Aufgaben bestehen, wie etwa Zubereiten einer Tütensuppe (einfach) Kochen einer Tomatensoße nach Rezept (mittel) Kochen von Milchreis (mittel) Zubereitung eines mehrgängigen Menüs ohne Rezept für 4 Personen (schwer) Welchen Aufgabenschwierigkeitsparamter man diesen drei Aufgaben zuweisen genau zuweisen würden, wie schwierig die Aufgaben also in relation zueinander sind, ist nicht bekannt. Ob zum Beispiel Aufgabe 2. oder 3. schwieriger ist, ist am Anfang schwer zu beurteilen. In realen Studien kann das bei der Erstellung der Aufgaben noch schlechter zu beurteilen sein. Lässt man nun eine Zahl von Probanden alle vier Aufgaben in beliebiger Reihenfolge bearbeiten und vermerkt Erfolg (Ergebnis genießbar) oder Misserfolg (nicht genießbar), so erhält man eine Liste mit den Ergebnissen der Personen als Zeilen und den Aufgaben als Spalten. Diese Form wird auch als tidy Data (aufgeräumte/ordentliche Daten) bezeichnet und ist die bevorzugte Form, in der Daten vorliegen sollten (Wickham 2014) oder * Tidy data. Mit diesen Daten kann eine Rasch Analyse gemacht werden, mit welcher man ein metrisches Maß für sowohl die Kochfähigkeit jedes einzelnen Probanden erhält (die Personenfähigkeitsparameter \\(\\theta_n\\)) als auch für die Schwierigkeit der einzelnen Aufgaben (die Aufgabenschwierigkeitsparameter \\(\\delta_i\\)) erhält. 2.1.2 Wie wird der beste Fit gefunden? Der beste Fit zwischen Modell und Daten, also der Satz von \\(\\theta_n\\) und \\(\\delta_i\\), der die beste Passung zwischen Modell und Daten liefert, kann über verschiedene Verfahren wie unter anderem das Least-quares- oder aber das Maximum-Likelihood-Verfahren gefunden werden (Linacre 1999). Bei letzterem wird durch ein iteratives Vorgehen, die sog. Likelihood-Funktion \\[ L_n= \\prod\\limits_{i}P(1/0|\\theta_n, \\delta_i)\\] für jede Personen \\(n\\) berechnet. Diese wird genau für den Personenfähigkeitsparameter maximal, für den die Wahrscheinlichkeit maximal wird, genau dieses Antwortverhalten auf die einzelnen Items zu bekommen. Es werden also die \\(\\theta_n\\) gesucht, für die die \\(L_n\\) maximal werden. Die Berechnung startet mit einer Schätzung der Itemschwierigkeit über den Anteil der Personen, die eine Aufgabe richtig bearbeitet haben \\[ \\delta_i = \\log\\left(\\frac{p}{1-p}\\right) \\] und sucht den Satz von Personenfähigkeitsparametern \\(\\theta_n\\), für den die Likelihood-Funktion maximal wird. Im nächsten Schritt wird mit diesen Satz von Personenfähigkeitsparametern \\(\\theta_n\\), die Likelihood-Funktion bezüglich der Itemschwierigkeitsparameter \\(\\delta_i\\) maximiert. So wird die Likelihood-Funktion immer weiter abwechseln bezüglich der \\(\\theta_n\\) und der \\(\\delta_i\\) maximiert. Dieser Vorgang sollte nach einer Zahl von Schritten konvergieren - sprich die Änderung der \\(theta_n\\) und \\(\\delta_i\\) wird immer kleiner und unterschreiter irgendwann einen festgelegten Wert. Dann wird die Iteration abgebrochen. Für einen Test mit zwei Items mit den Schwierigkeitsparametern (\\(\\delta_1 = -1\\), \\(\\delta_1 = 0.5\\)) wäre die Likelihood-Funktion eines Probanden mit einer richtigen Antwort im ersten Item und einer falschen im zweiten Item: \\[L(\\theta) = P(1|\\theta, \\delta_1 = -1) \\cdot P(0|\\theta, \\delta_2 = 0.5)\\\\ = \\left(\\frac{\\exp(\\theta + 1)}{1+\\exp(\\theta + 1)}\\right)\\cdot\\left(1-\\frac{\\exp(\\theta - 0.5)}{1+\\exp(\\theta - 0.5)}\\right)\\] Für diese muss nun das Maximum bezüglich \\(\\theta\\) gefunden werden. An dieser Stelle gibt es verschiedene Schätzmethoden für die Itemschwierigkeits- und Personenfähigkeitsparameter wie die Joint-Maximum-Likelihood-Schätzung (JML) und die Weighted Likelihood Schätzung (WLE), welche ein Bias in der Schätzung mit JML verringert. Die genauen Details dieser verschiedenen Verfahren sollen an dieser Stelle aber nicht weiter behandelt werden. 2.1.3 zum Weiterschauen Sehr interessante Videos zu diesem Thema, die das Ganze noch einmal wesentlich umfangreicher beschreiben, sind: A Conceptual Introduction to Item Response Theory Logistic Regression 2.2 Der Datensatz Der für diese Erklärung verwendete Datensatz stammt aus dem Paket TAM und hat das Format einer einfachen Matrix. Es handelt sich um simulierte Daten von 2000 Probanden (als Zeilen) zu jeweils 40 Items (als Spalten). Die Spalten für die einzelnen Items sind mit I1 bis I40 bezeichnet. Eine Spalte für eine Probanden ID oder ähnliches gibt es nicht. Auch hat der Datensatz keine fehlenden Daten, d.h. zu jedem Probanden gibt es Daten zu jedem Item. Die Items selbst sind alle dichotom (richtig/falsch) und mit 1 und 0 codiert. data(data.sim.rasch) head(data.sim.rasch) ## I1 I2 I3 I4 I5 I6 I7 I8 I9 I10 I11 I12 I13 I14 I15 I16 I17 I18 I19 I20 I21 ## [1,] 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 ## [2,] 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 ## [3,] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 ## [4,] 1 0 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 0 0 ## [5,] 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 ## [6,] 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 ## I22 I23 I24 I25 I26 I27 I28 I29 I30 I31 I32 I33 I34 I35 I36 I37 I38 I39 ## [1,] 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [2,] 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 ## [3,] 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 ## [4,] 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 ## [5,] 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 ## [6,] 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 ## I40 ## [1,] 0 ## [2,] 0 ## [3,] 1 ## [4,] 0 ## [5,] 0 ## [6,] 0 References "],
["item-analyse.html", "3 Item Analyse 3.1 Laden der benötigten Pakete und des Datensatzes 3.2 Modellschätzung 3.3 Erzeugen einer Wright-Map 3.4 ICC (Item Characteristic Curve)", " 3 Item Analyse 3.1 Laden der benötigten Pakete und des Datensatzes library(TAM) # TAM-Paket ## Loading required package: CDM ## Loading required package: mvtnorm ## ********************************** ## ** CDM 7.5-15 (2020-03-10 14:19:21) ## ** Cognitive Diagnostic Models ** ## ********************************** ## * TAM 3.5-19 (2020-05-05 22:45:39) library(WrightMap) # zur Erzeugung von Wright-Maps library(RColorBrewer) # für schönere Farben in den Wright-Maps data(data.sim.rasch) # data.sim.rasch: 2000 persons, 40 items Das R-Paket “TAM” (Robitzsch, A., Kiefer, T., &amp; Wu, M. (2019). TAM: Test Analysis Modules. R package version 3.3-10. https://CRAN.R-project.org/package=TAM) ist freie Software unter der Lizenz GNU General Public License. 3.2 Modellschätzung Der Befehl erzeugt ein Listen-Objekt mit vielen Einträgen. Folgend wird ein Dataframe-Objekt aus dieser Liste ausgewählt und ausgegeben. Es enthält verschiedene Spalten mit deskriptiven Kennwerten: mod1PL$item ## item N M xsi.item AXsi_.Cat1 B.Cat1.Dim1 ## I1 I1 2000 0.8270 -1.95906755 -1.95906755 1 ## I2 I2 2000 0.8145 -1.85707784 -1.85707784 1 ## I3 I3 2000 0.8000 -1.74448741 -1.74448741 1 ## I4 I4 2000 0.7860 -1.64079925 -1.64079925 1 ## I5 I5 2000 0.7725 -1.54485365 -1.54485365 1 ## I6 I6 2000 0.7710 -1.53441512 -1.53441512 1 ## I7 I7 2000 0.7430 -1.34668186 -1.34668186 1 ## I8 I8 2000 0.7435 -1.34992594 -1.34992594 1 ## I9 I9 2000 0.7295 -1.26040238 -1.26040238 1 ## I10 I10 2000 0.6945 -1.04694135 -1.04694135 1 ## I11 I11 2000 0.6905 -1.02335166 -1.02335166 1 ## I12 I12 2000 0.6615 -0.85638275 -0.85638275 1 ## I13 I13 2000 0.6515 -0.80026553 -0.80026553 1 ## I14 I14 2000 0.6415 -0.74479292 -0.74479292 1 ## I15 I15 2000 0.6000 -0.52027584 -0.52027584 1 ## I16 I16 2000 0.5765 -0.39628492 -0.39628492 1 ## I17 I17 2000 0.5720 -0.37273730 -0.37273730 1 ## I18 I18 2000 0.5445 -0.22987456 -0.22987456 1 ## I19 I19 2000 0.5205 -0.10621935 -0.10621935 1 ## I20 I20 2000 0.5100 -0.05228424 -0.05228424 1 ## I21 I21 2000 0.4925 0.03753652 0.03753652 1 ## I22 I22 2000 0.4795 0.10429854 0.10429854 1 ## I23 I23 2000 0.4350 0.33421807 0.33421807 1 ## I24 I24 2000 0.4180 0.42310019 0.42310019 1 ## I25 I25 2000 0.3995 0.52082702 0.52082702 1 ## I26 I26 2000 0.3770 0.64147566 0.64147566 1 ## I27 I27 2000 0.3765 0.64418273 0.64418273 1 ## I28 I28 2000 0.3395 0.84834994 0.84834994 1 ## I29 I29 2000 0.3235 0.93942118 0.93942118 1 ## I30 I30 2000 0.3100 1.01785330 1.01785330 1 ## I31 I31 2000 0.2935 1.11597708 1.11597708 1 ## I32 I32 2000 0.2900 1.13714364 1.13714364 1 ## I33 I33 2000 0.2620 1.31159123 1.31159123 1 ## I34 I34 2000 0.2615 1.31479716 1.31479716 1 ## I35 I35 2000 0.2255 1.55581073 1.55581073 1 ## I36 I36 2000 0.2165 1.61968818 1.61968818 1 ## I37 I37 2000 0.2050 1.70383560 1.70383560 1 ## I38 I38 2000 0.1990 1.74896980 1.74896980 1 ## I39 I39 2000 0.1755 1.93517136 1.93517136 1 ## I40 I40 2000 0.1620 2.05013862 2.05013862 1 N: Anzahl an Personen, die das jeweilige Item bearbeitet haben. M: Deskriptive Schwierigkeit des Items (\\(M = \\frac{N_{korrekt}}{N_{gelöst}}\\)). xsi.item: xsi wird ausgesprochen wie geschrieben und bezieht sich auf den griechischen Buchstaben. Der \\(\\xi\\)-Parameter ist die, mit dem Modell geschätzte, Aufgabenschwierigkeit auf der Skala von \\(-\\infty\\) bis \\(\\infty\\) mit 0 als Mittelwert. Übliche Werte in der Praxis liegen zwischen -3 bis 3. Eine Aufgabe mit Schwierigkeit \\(\\xi=1\\) ist dabei schwerer als eine Aufgabe mit Schwierigkeit \\(\\xi=0\\). Oft findet man den Schwierigkeitsparameter auch unter anderen griechischen Buchstaben in der Literatur, z. B. \\(\\delta\\) oder \\(\\beta\\). TAM übernimmt die Notation mit \\(\\beta\\) unter der Bezeichnung IRT parametrization. Siehe dazu den folgenden Output. mod1PL$item_irt ## item alpha beta ## 1 I1 1 -1.95906755 ## 2 I2 1 -1.85707784 ## 3 I3 1 -1.74448741 ## 4 I4 1 -1.64079925 ## 5 I5 1 -1.54485365 ## 6 I6 1 -1.53441512 ## 7 I7 1 -1.34668186 ## 8 I8 1 -1.34992594 ## 9 I9 1 -1.26040238 ## 10 I10 1 -1.04694135 ## 11 I11 1 -1.02335166 ## 12 I12 1 -0.85638275 ## 13 I13 1 -0.80026553 ## 14 I14 1 -0.74479292 ## 15 I15 1 -0.52027584 ## 16 I16 1 -0.39628492 ## 17 I17 1 -0.37273730 ## 18 I18 1 -0.22987456 ## 19 I19 1 -0.10621935 ## 20 I20 1 -0.05228424 ## 21 I21 1 0.03753652 ## 22 I22 1 0.10429854 ## 23 I23 1 0.33421807 ## 24 I24 1 0.42310019 ## 25 I25 1 0.52082702 ## 26 I26 1 0.64147566 ## 27 I27 1 0.64418273 ## 28 I28 1 0.84834994 ## 29 I29 1 0.93942118 ## 30 I30 1 1.01785330 ## 31 I31 1 1.11597708 ## 32 I32 1 1.13714364 ## 33 I33 1 1.31159123 ## 34 I34 1 1.31479716 ## 35 I35 1 1.55581073 ## 36 I36 1 1.61968818 ## 37 I37 1 1.70383560 ## 38 I38 1 1.74896980 ## 39 I39 1 1.93517136 ## 40 I40 1 2.05013862 AXsi_.Cat1: Schwierigkeit, gegeben, dass das Item verschiedenen Personengruppen und/oder Testheften zugeordnet wurde und unter den jeweiligen Bedingungen unterschiedlich erfolgreich bearbeitet wurde. Da hier nur ein eindimensionales Modell ohne weitere Bedingungen berechnet wurde, entspricht der Wert dem \\(\\xi\\)-Parameter. B.Cat1.Dim1: Steigungsparameter. Im eindimensionalen 1-PL-Modell wird der B-Parameter nicht berechnet, sondern auf \\(B=1\\) fixiert. Oft findet man den Steigungsparameter auch unter der Bezeichnung \\(\\alpha\\) (siehe Output oben zu xsi.item). 3.3 Erzeugen einer Wright-Map thetas_1pl &lt;- tam.wle(mod1PL) # WLEs berechnen ## Iteration in WLE/MLE estimation 1 | Maximal change 0.8281 ## Iteration in WLE/MLE estimation 2 | Maximal change 0.4335 ## Iteration in WLE/MLE estimation 3 | Maximal change 0.0883 ## Iteration in WLE/MLE estimation 4 | Maximal change 7e-04 ## Iteration in WLE/MLE estimation 5 | Maximal change 0 ## ---- ## WLE Reliability= 0.894 item_xsis_1pl &lt;- mod1PL$xsi$xsi # Itemschwierigkeiten separieren wrightMap(thetas_1pl$theta, item_xsis_1pl, item.side = itemClassic, main.title = &quot;Beispiel für Wright-Map&quot;, axis.persons = &quot;Fähigkeitsverteilung&quot;, axis.items = &quot;Aufgabenverteilung&quot;) ## [,1] ## [1,] -1.95901708 ## [2,] -1.85702665 ## [3,] -1.74443543 ## [4,] -1.64074652 ## [5,] -1.54480023 ## [6,] -1.53436162 ## [7,] -1.34662700 ## [8,] -1.34987110 ## [9,] -1.26034689 ## [10,] -1.04688427 ## [11,] -1.02329441 ## [12,] -0.85632426 ## [13,] -0.80020663 ## [14,] -0.74473359 ## [15,] -0.52021484 ## [16,] -0.39622299 ## [17,] -0.37267520 ## [18,] -0.22981140 ## [19,] -0.10615527 ## [20,] -0.05221976 ## [21,] 0.03760166 ## [22,] 0.10436417 ## [23,] 0.33428538 ## [24,] 0.42316815 ## [25,] 0.52089569 ## [26,] 0.64154518 ## [27,] 0.64425227 ## [28,] 0.84842093 ## [29,] 0.93949280 ## [30,] 1.01792547 ## [31,] 1.11604992 ## [32,] 1.13721663 ## [33,] 1.31166540 ## [34,] 1.31487135 ## [35,] 1.55588652 ## [36,] 1.61976438 ## [37,] 1.70391234 ## [38,] 1.74904684 ## [39,] 1.93524957 ## [40,] 2.05021754 3.4 ICC (Item Characteristic Curve) 3.4.1 Input Item Characterisitc Curves geben die Lösungswahrscheinlichkeit als Funktion der Fähigkeit der Probanden an. Dabei stellt die y-Achse die Lösungswahrscheinlichkeit und x-Achse die Probandenfähigkeit dar. 3.4.2 R-Befehl für Generierung ICC in TAM Erstellung der ICC für Item 20 mit Gruppierung der Personenfähigkeiten in 6 Gruppen im Rasch-Modell: plot(mod1, items = 20, ngroups = 6, export = FALSE) # export = FALSE verhindert separates Abspeichern der .png-Datei ## Iteration in WLE/MLE estimation 1 | Maximal change 0.8281 ## Iteration in WLE/MLE estimation 2 | Maximal change 0.4335 ## Iteration in WLE/MLE estimation 3 | Maximal change 0.0883 ## Iteration in WLE/MLE estimation 4 | Maximal change 7e-04 ## Iteration in WLE/MLE estimation 5 | Maximal change 0 ## ---- ## WLE Reliability= 0.894 3.4.3 Interpretation ICC im Rasch-Modell (s. Wu et al. 2016) Ausführungen beziehen sich auf Item 20, s. obigen Plot blaue Kurve: Modellkurve (vom Modell vorhergesagter Zusammenhang zw. Fähigkeit und Lösungswahrscheinlichkeit) –&gt; Probanden mit einer Fähigkeitsausprägung von 1, lösen das Item mit 75%iger Wahrscheinlichkeit richtig gepunktete schwarze Kurve: empirische Kurve (beobachtete Lösungswahrscheinlichkeit bzw. Lösungsquote) –&gt; etwa 76 % der Probanden mit der Fähigkeitsausprägung (ability) = 1 lösten das Item richtig –&gt; Bei diesem Beispiel (Item 20) liegt eine gute Passung beider Kurven vor, d.h. das Modell beschreibt das Item sehr gut. 3.4.3.1 Misfits Für die Beurteilung von Items, kann die Passung der empirischen Kurve zur Modellkurve herangezogen werden. Dabei muss nicht immer die empirische Kurve gut zur Modellkurve passen –&gt; misfits Es wird dabei zw. overfit und underift unterschieden. Overfit: wMNSQ-Wert (Infit) &lt; 1; empirische Kurve steiler als Modellkurve; entspricht hoher discrimination –&gt; item unterscheidet Probanden verschiedener Fähigkeitsausprägungen besser als andere Items im Test Underfit: wMNSQ-Wert (Infit) &gt; 1; empirische Kurve steiler als Modellkurve; entspricht geringerer discrimination Es wird empfohlen, Items mit einem Overfit zu behalten und Items mit einem Underfit aus dem Test zu entfernen. Dieses Vorgehen zeigt einen Einfluss auf die EAP-Reliabilität (s. Wu et al. 2016 p. 153) 3.4.4 Gegenüberstellung leichtes - schweres Item mod1$xsi # Itemschwierigkeiten xsi aller Items ## xsi se.xsi ## I1 -1.95901708 0.06465854 ## I2 -1.85702665 0.06311470 ## I3 -1.74443543 0.06153710 ## I4 -1.64074652 0.06019663 ## I5 -1.54480023 0.05904820 ## I6 -1.53436162 0.05892844 ## I7 -1.34662700 0.05694173 ## I8 -1.34987110 0.05697344 ## I9 -1.26034689 0.05613124 ## I10 -1.04688427 0.05438831 ## I11 -1.02329441 0.05421784 ## I12 -0.85632426 0.05313222 ## I13 -0.80020663 0.05281391 ## I14 -0.74473359 0.05252176 ## I15 -0.52021484 0.05156219 ## I16 -0.39622299 0.05118169 ## I17 -0.37267520 0.05112121 ## I18 -0.22981140 0.05083401 ## I19 -0.10615527 0.05069507 ## I20 -0.05221976 0.05066614 ## I21 0.03760166 0.05066059 ## I22 0.10436417 0.05069098 ## I23 0.33428538 0.05102212 ## I24 0.42316815 0.05124518 ## I25 0.52089569 0.05155264 ## I26 0.64154518 0.05202355 ## I27 0.64425227 0.05203529 ## I28 0.84842093 0.05307253 ## I29 0.93949280 0.05363422 ## I30 1.01792547 0.05416852 ## I31 1.11604992 0.05490459 ## I32 1.13721663 0.05507343 ## I33 1.31166540 0.05660515 ## I34 1.31487135 0.05663570 ## I35 1.55588652 0.05919171 ## I36 1.61976438 0.05995850 ## I37 1.70391234 0.06102867 ## I38 1.74904684 0.06163154 ## I39 1.93524957 0.06434122 ## I40 2.05021754 0.06620206 Item 1 plot(mod1, items = 1, ngroups = 6, export = FALSE) # xsi = -1.96 ## Iteration in WLE/MLE estimation 1 | Maximal change 0.8281 ## Iteration in WLE/MLE estimation 2 | Maximal change 0.4335 ## Iteration in WLE/MLE estimation 3 | Maximal change 0.0883 ## Iteration in WLE/MLE estimation 4 | Maximal change 7e-04 ## Iteration in WLE/MLE estimation 5 | Maximal change 0 ## ---- ## WLE Reliability= 0.894 Item 40 plot(mod1, items = 40, ngroups = 6, export = FALSE) # xsi = 2.05 ## Iteration in WLE/MLE estimation 1 | Maximal change 0.8281 ## Iteration in WLE/MLE estimation 2 | Maximal change 0.4335 ## Iteration in WLE/MLE estimation 3 | Maximal change 0.0883 ## Iteration in WLE/MLE estimation 4 | Maximal change 7e-04 ## Iteration in WLE/MLE estimation 5 | Maximal change 0 ## ---- ## WLE Reliability= 0.894 3.4.4.1 Interpretation Probanden mit einer geschätzten Fähigkeit von 0 lösen diese beiden Items mit unterschiedlichen Lösungswahrscheinlichkeiten. Während Probanden mit einer Fähigkeitsausprägung von 0 das Item 1 mit etwa 90%iger Wahrscheinlichkeit richtig lösen, lösen diese das Item 40 mit einer etwa 15%igen Lösungswahrscheinlichkeit. 3.4.5 Gegenüberstellung ICC Rasch - 2PL Item 40 Rasch plot(mod1, items = 40, ngroups = 6, export = FALSE) # Steigungsparameter = 1 ## Iteration in WLE/MLE estimation 1 | Maximal change 0.8281 ## Iteration in WLE/MLE estimation 2 | Maximal change 0.4335 ## Iteration in WLE/MLE estimation 3 | Maximal change 0.0883 ## Iteration in WLE/MLE estimation 4 | Maximal change 7e-04 ## Iteration in WLE/MLE estimation 5 | Maximal change 0 ## ---- ## WLE Reliability= 0.894 Item 40 2PL plot(mod2, items = 40, ngroups = 6, export = FALSE) # Steigungsparameter frei geschätzt ## Iteration in WLE/MLE estimation 1 | Maximal change 0.3445 ## Iteration in WLE/MLE estimation 2 | Maximal change 0.0677 ## Iteration in WLE/MLE estimation 3 | Maximal change 5e-04 ## Iteration in WLE/MLE estimation 4 | Maximal change 0 ## ---- ## WLE Reliability= 0.894 3.4.5.1 Deutung Beim 2PL Modell wird der Steigungsparamter für jedes Item frei geschätzt. Das zeigt sich unter anderem in den ICCs. Durch das Vorliegen des simulierten Datensatzes zeigt sich kein merkbarer Unterschied in den ICCs des Rasch und 2PL Modell. Dennoch sei an dieser Stelle angemerkt, dass es beim 2PL Modell durchaus zu ICCs kommen kann, die negative Steigungen aufweisen. Die Interpretation dahinter wäre: Bei steigender Probandenfähigkeit, sinkt die Lösungswahrscheinlichkeit des Items. Dies kann ein Indiz für ein nicht funktionierendes Item sein, aber ebenso ein Hinweis auf eine Mehrdimensionalität des Konstruktes (Bühner, 2011, p.506; Chalmers, 2015, p. 216). Jenes Item könnte demnach in eine andere Dimension fallen. "],
["typische-fehlvorstellungen.html", "4 Typische Fehlvorstellungen 4.1 “Das Rasch-Modell berücksichtigt im Gegensatz zur klassischen Testtheorie, welche Aufgaben richtig bearbeitet werden” 4.2 Anwendung eines t-Tests für unabhängige Stichproben auf abhängige Stichproben 4.3 Weitere", " 4 Typische Fehlvorstellungen Im Laufe unserer Zeit sind wir immer wieder einigen Fehlvorstellungen und Fehlern begegnet. Einigen davon sind wir auch selbst erlegen gewesen bzw. haben wir selbst gemacht. Im Folgenden stellen wir diese Vorstellungen und Fehler kurz vor und stellen sie einer fachlich angemessenen Beschreibung gegenüber. 4.1 “Das Rasch-Modell berücksichtigt im Gegensatz zur klassischen Testtheorie, welche Aufgaben richtig bearbeitet werden” Im Folgenden soll, was sich hinter dieser Vorstellung verbirgt, genauer beschrieben werden: Person A und B haben beide 2 Punkte im Test erreicht: * Person A * gelöst: Aufgabe 1 (leicht) und 2 (mittelschwer) * nicht gelöst: Aufgabe 3 (schwer) * Person B * gelöst: Aufgabe 1 (leicht) und Aufgabe 3 (schwer) * nicht gelöst: Aufgabe 3 (schwer) Eine typische Fehlvorstellung ist, anzunehmen, dass die richtige Bearbeitung von Aufgabe 3 im Rasch-Modell zu einer höheren Personenfähigkeit führt und somit für Person A ein niedrigerer Fähigkeitsparameter geschätzt würde als für Person B. Das stimmt aber so nicht: Es wird von der Punktesumme direkt auf den Fähigkeitsparameter geschlossen (wenn alle Teilnehmenden, die gleichen Aufgaben bearbeitet haben). Es ist dennoch so, dass sich Person B nicht Rasch-Modell konform verhält: Wenn nur eine Art von Fähigkeit (z.B. die Fähigkeit zwei normale Zahlen zu addieren) verantwortlich ist für das Lösungsverhalten auf den Aufgaben, warum kann eine Person dann Aufgabe 3 richtig bearbeiten aber nicht Aufgabe 2, wobei Aufgabe 2 doch leichter sein sollte? Das Verhalten der Person B geht insofern in die Rasch-Analyse ein, als sich das Verhalten von Person B als Residuum bemerkbar macht und so z.B. in die MNSQ von Aufgabe 2 zwei und drei einfließt. 4.2 Anwendung eines t-Tests für unabhängige Stichproben auf abhängige Stichproben Eine typische Analyse in der Lehr-Lern-Forschung ist die Überprüfung des Lernzuwachses einer Lerngruppe. Häufig sieht man, dass hier ein t-Test für unabhängige Stichproben verwendet wird, wobei es doch um den individuellen Lernzuwachs geht. Besser wäre es deshalb hier einen Test für abhängige Stichproben zu verwenden. Dabei werden Paare von einzelnen Fähigkeitsparametern nach Personen gebildet (was auch einem t-Test der Differenzen der Fähigkeitsparameter (nach der Lerneinheit minus vor der Lerneinheit) gegen den theoretischen Wert 0 entspricht. 4.3 Weitere 4.3.1 Ist die Faktoranalyse ein Teil der klassischen Testtheorie 4.3.2 PCA ist dasselbe wie Faktoranalyse Linacre, John M. 1999. “Understanding Rasch Measurement: Estimation Methods for Rasch Measures.” Journal of Outcome Measurement 3: 381–405. Wickham, Hadley. 2014. “Tidy Data.” The Journal of Statistical Software 59 (10). http://www.jstatsoft.org/v59/i10/. "]
]
