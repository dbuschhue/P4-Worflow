# Typische Fehlvorstellungen

Im Laufe der Zeit sind wir immer wieder einigen Fehlvorstellungen und Fehlern begegnet - vornehmlich bei uns selbst. Im Folgenden stellen wir diese Vorstellungen und Fehler kurz vor und stellen sie einer fachlich angemessenen Beschreibung gegenüber.


## „Das Rasch-Modell berücksichtigt im Gegensatz zur klassischen Testtheorie, welche Aufgaben richtig bearbeitet werden“ 

*Autor: David Buschhüter*

Im Folgenden soll, was sich hinter dieser Vorstellung verbirgt, genauer beschrieben werden:
Person A und B haben beide 2 Punkte im Test erreicht: 

* Person A
    + gelöst: Aufgabe 1 (leicht) und 2 (mittelschwer) 
    + nicht gelöst: Aufgabe 3 (schwer)
* Person B
    + gelöst: Aufgabe 1 (leicht) und 3 (schwer)
    + nicht gelöst: Aufgabe 2 (mittelschwer)

Eine typische Fehlvorstellung ist, anzunehmen, dass die richtige Bearbeitung von Aufgabe 3 im Rasch-Modell zu einer höheren Personenfähigkeit führt und somit für Person A ein niedrigerer Fähigkeitsparameter geschätzt würde als für Person B.

Das stimmt aber so nicht: Es wird von der Punktesumme direkt auf den Fähigkeitsparameter geschlossen (wenn alle Teilnehmenden, die gleichen Aufgaben bearbeitet haben).

Es ist dennoch so, dass sich Person B nicht Rasch-Modell konform verhält: Wenn nur eine Art von Fähigkeit (z.B. die Fähigkeit zwei normale Zahlen zu addieren) verantwortlich ist für das Lösungsverhalten auf den Aufgaben, warum kann eine Person dann Aufgabe 3 richtig bearbeiten aber nicht Aufgabe 2, wobei Aufgabe 2 doch leichter sein sollte? Dies ist im Rahmen des Modells (sinnvollerweise) kein erwartetes Verhalten.

Hier kurz eine Illustration anhand der simulierten Daten. Wir nutzen dabei der übersichtlichkeit halber nur 10 Aufgaben.


```r
# laden von Paket und Daten
library(TAM)
data(data.sim.rasch) # Items in den Spalten 1(einfachstes)- 40(schwierigstes)
class(data.sim.rasch)
df <- as.data.frame(data.sim.rasch)

# Wir nutzen nur 10 der items und verteilen Sie über das Schwierigkeitsspektrum
id_items <- paste0("I",seq(from = 1, to = 40, by = 4))
df <- df[,id_items] 

# Wir erzeugen zwei künstliche Personen
PersonA <- rep(1, 10)
PersonB <- rep(1, 10)

# Folgendes ist nur möglich, weil die Items in aufsteigender 
# Schwierigkeit angeordnet sind
# Person A hat Item 7 bis 10 nicht richtig gelöst
PersonA[7:10] <- 0
# Person B hat die Items 5 bis 8 nicht richtig gelöst
PersonB[5:8] <- 0

# Wir setzen die beiden Person unter die Daten
df <- rbind(df, PersonA, PersonB)
```

Im Folgenden führen wir unsere Modellschätzung durch und bestimmen die WLEs.


```r
mod1 <- tam.mml(df)
pers_wle <- tam.wle(mod1)
```


Nun betrachten wir die Personen und können feststellen, dass beide Personen, die gleiche Punktsumme und damit den gleichen WLE haben. Obowohl sie unterschiedlich schwere Items falsch (bzw. richtig) bearbeitet haben



```r
#Person A
paste0("Person A Punkte:", pers_wle$PersonScores[2001],
      " -- WLE: ", pers_wle$theta[2001])

#Person B
paste0("Person B Punkte:", pers_wle$PersonScores[2002],
      " -- WLE: ", pers_wle$theta[2002])
```

```
## [1] "Person A Punkte:6 -- WLE: 0.368938295521783"
## [1] "Person B Punkte:6 -- WLE: 0.368938295521783"
```

Auch in einer Kreuztabelle zeigt sich, dass jeder Punktsumme ein Personenparameter zugeordnet ist.


```r
table(pers_wle$theta, pers_wle$PersonScores)
```

```
##                     
##                        0   1   2   3   4   5   6   7   8   9  10
##   -3.8455129473403    29   0   0   0   0   0   0   0   0   0   0
##   -2.53353632886603    0  91   0   0   0   0   0   0   0   0   0
##   -1.78796492184948    0   0 174   0   0   0   0   0   0   0   0
##   -1.19340354202589    0   0   0 200   0   0   0   0   0   0   0
##   -0.658440981659926   0   0   0   0 267   0   0   0   0   0   0
##   -0.14536035670342    0   0   0   0   0 303   0   0   0   0   0
##   0.368938295521783    0   0   0   0   0   0 292   0   0   0   0
##   0.907248431737066    0   0   0   0   0   0   0 275   0   0   0
##   1.50654116366944     0   0   0   0   0   0   0   0 200   0   0
##   2.25735722362073     0   0   0   0   0   0   0   0   0 127   0
##   3.5743098371099      0   0   0   0   0   0   0   0   0   0  44
```


## Anwendung eines t-Tests für unabhängige Stichproben auf abhängige Stichproben

*Autor: David Buschhüter*

Eine typische Analyse in der Lehr-Lern-Forschung ist die Überprüfung des Lernzuwachses einer Lerngruppe. Häufig sieht man, dass hier ein t-Test für unabhängige Stichproben verwendet wird, wobei es doch um den individuellen Lernzuwachs geht.
 
Besser wäre es deshalb, hier einen Test für abhängige Stichproben zu verwenden. Dabei werden Paare von einzelnen Fähigkeitsparametern nach Personen gebildet (was auch einem t-Test der Differenzen der Fähigkeitsparameter (nach der Lerneinheit minus vor der Lerneinheit) gegen den theoretischen Wert 0 entspricht. 

https://www.r-bloggers.com/2009/07/paired-students-t-test/



