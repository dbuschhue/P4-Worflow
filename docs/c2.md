---
output: 
  html_document:
    code_folding: show
---

## Laden der benötigten Pakete und des Datensatzes
Da jede Anwendung der Software _R_ die Nutzung von Paketen vorsieht, sind diese hier aufgelistet. Der geladene Datensatz wird mit dem "TAM"-Paket mitgeliefert.



```r
library(TAM) # TAM-Paket als zentrales Paket
library(WrightMap) # zur Erzeugung von Wright-Maps
data(data.sim.rasch) # Lerndatensatz mit 2000 Personen & 40 Items, integriert in das TAM-Paket
```

### Paketquellen
- "TAM" [@TAM2020]
- "WrightMap" [@WrightMap2016]

## Modellschätzung
Der folgende Code initiiert die Schätzung eines Rasch-Modells für den vorliegenden Datensatz. Das Listen-Objekt `mod1PL` mit 57 Sublisten wird erzeugt. Außerdem wird ein umfänglicher Konsolen-Output sichtbar. Dieser wird im Folgenden erläutert, es wird sich auf die mit Punkten getrennten Teilabschnitte bezogen.


```r
mod1PL <- TAM::tam.mml(resp=data.sim.rasch)
```

```
## ....................................................
## Processing Data      2022-09-13 08:53:33 
##     * Response Data: 2000 Persons and  40 Items 
##     * Numerical integration with 21 nodes
##     * Created Design Matrices   ( 2022-09-13 08:53:33 )
##     * Calculated Sufficient Statistics   ( 2022-09-13 08:53:33 )
## ....................................................
## Iteration 1     2022-09-13 08:53:33
## E Step
## M Step Intercepts   |----
##   Deviance = 84803.9272
##   Maximum item intercept parameter change: 0.33272
##   Maximum item slope parameter change: 0
##   Maximum regression parameter change: 0
##   Maximum variance parameter change: 0.125876
## ....................................................
## Iteration 2     2022-09-13 08:53:33
## E Step
## M Step Intercepts   |---
##   Deviance = 84201.8406 | Absolute change: 602.0866 | Relative change: 0.00715052
##   Maximum item intercept parameter change: 0.044568
##   Maximum item slope parameter change: 0
##   Maximum regression parameter change: 0
##   Maximum variance parameter change: 0.167316
## ....................................................
## Iteration 3     2022-09-13 08:53:33
## E Step
## M Step Intercepts   |--
##   Deviance = 84162.1461 | Absolute change: 39.6945 | Relative change: 0.00047164
##   Maximum item intercept parameter change: 0.017468
##   Maximum item slope parameter change: 0
##   Maximum regression parameter change: 0
##   Maximum variance parameter change: 0.069771
## ....................................................
## Iteration 4     2022-09-13 08:53:33
## E Step
## M Step Intercepts   |--
##   Deviance = 84156.6153 | Absolute change: 5.5308 | Relative change: 6.572e-05
##   Maximum item intercept parameter change: 0.006594
##   Maximum item slope parameter change: 0
##   Maximum regression parameter change: 0
##   Maximum variance parameter change: 0.026369
## ....................................................
## Iteration 5     2022-09-13 08:53:33
## E Step
## M Step Intercepts   |--
##   Deviance = 84155.879 | Absolute change: 0.7363 | Relative change: 8.75e-06
##   Maximum item intercept parameter change: 0.00247
##   Maximum item slope parameter change: 0
##   Maximum regression parameter change: 0
##   Maximum variance parameter change: 0.00966
## ....................................................
## Iteration 6     2022-09-13 08:53:33
## E Step
## M Step Intercepts   |--
##   Deviance = 84155.7823 | Absolute change: 0.0966 | Relative change: 1.15e-06
##   Maximum item intercept parameter change: 0.000952
##   Maximum item slope parameter change: 0
##   Maximum regression parameter change: 0
##   Maximum variance parameter change: 0.0035
## ....................................................
## Iteration 7     2022-09-13 08:53:33
## E Step
## M Step Intercepts   |--
##   Deviance = 84155.7696 | Absolute change: 0.0128 | Relative change: 1.5e-07
##   Maximum item intercept parameter change: 0.000396
##   Maximum item slope parameter change: 0
##   Maximum regression parameter change: 0
##   Maximum variance parameter change: 0.001263
## ....................................................
## Iteration 8     2022-09-13 08:53:33
## E Step
## M Step Intercepts   |--
##   Deviance = 84155.7678 | Absolute change: 0.0018 | Relative change: 2e-08
##   Maximum item intercept parameter change: 0.00019
##   Maximum item slope parameter change: 0
##   Maximum regression parameter change: 0
##   Maximum variance parameter change: 0.000455
## ....................................................
## Iteration 9     2022-09-13 08:53:33
## E Step
## M Step Intercepts   |--
##   Deviance = 84155.7674 | Absolute change: 4e-04 | Relative change: 0
##   Maximum item intercept parameter change: 0.000111
##   Maximum item slope parameter change: 0
##   Maximum regression parameter change: 0
##   Maximum variance parameter change: 0.000164
## ....................................................
## Iteration 10     2022-09-13 08:53:33
## E Step
## M Step Intercepts   |-
##   Deviance = 84155.7672 | Absolute change: 2e-04 | Relative change: 0
##   Maximum item intercept parameter change: 7.9e-05
##   Maximum item slope parameter change: 0
##   Maximum regression parameter change: 0
##   Maximum variance parameter change: 5.9e-05
## ....................................................
## Item Parameters
##    xsi.index xsi.label     est
## 1          1        I1 -1.9590
## 2          2        I2 -1.8570
## 3          3        I3 -1.7444
## 4          4        I4 -1.6407
## 5          5        I5 -1.5448
## 6          6        I6 -1.5344
## 7          7        I7 -1.3466
## 8          8        I8 -1.3499
## 9          9        I9 -1.2603
## 10        10       I10 -1.0469
## 11        11       I11 -1.0233
## 12        12       I12 -0.8563
## 13        13       I13 -0.8002
## 14        14       I14 -0.7447
## 15        15       I15 -0.5202
## 16        16       I16 -0.3962
## 17        17       I17 -0.3727
## 18        18       I18 -0.2298
## 19        19       I19 -0.1062
## 20        20       I20 -0.0522
## 21        21       I21  0.0376
## 22        22       I22  0.1044
## 23        23       I23  0.3343
## 24        24       I24  0.4232
## 25        25       I25  0.5209
## 26        26       I26  0.6415
## 27        27       I27  0.6443
## 28        28       I28  0.8484
## 29        29       I29  0.9395
## 30        30       I30  1.0179
## 31        31       I31  1.1160
## 32        32       I32  1.1372
## 33        33       I33  1.3117
## 34        34       I34  1.3149
## 35        35       I35  1.5559
## 36        36       I36  1.6198
## 37        37       I37  1.7039
## 38        38       I38  1.7490
## 39        39       I39  1.9352
## 40        40       I40  2.0502
## ...................................
## Regression Coefficients
##      [,1]
## [1,]    0
## 
## Variance:
##       [,1]
## [1,] 1.404
## 
## 
## EAP Reliability:
## [1] 0.899
## 
## -----------------------------
## Start:  2022-09-13 08:53:33
## End:  2022-09-13 08:53:33 
## Time difference of 0.299269 secs
```

- `## Processing Data`: Mit Uhrzeit und Datum versehener Diagnoseabschnitt. `Calculated Sufficient Statistics` bestätigt für das Raschmodell, dass ausreichend viele Personen ausreichend viele Aufgaben bearbeitet haben. Weitere Details werden an dieser Stelle nicht ausgeführt, es sei lediglich darauf hingewiesen, dass die Berechnung bereits an dieser Stelle abgebrochen werden kann. Dies geschieht bspw. wenn ein fehlerhafter Datensatz vorliegt, der von der Funktion nicht lesbar ist.

- `Iteration 1` bis `Iteration 10`: Hier werden iterativ die Modellparameter geschätzt (vgl. Abschnitt [4.1.2][Wie wird der beste Fit gefunden?]). Weil im Raschmodell nur die Schwierigkeit (`item intercept parameter`) und keine Steigung (`item slope parameter`) und kein Einfluss von Hintergrundvariablen (`regression parameter`) in das Modell eingebaut wurden, sind diese konstant $0$. Gut erkennbar ist das kontinuierliche Absinken der `Deviance`-Änderung (`Absolute change` & `Relative change`): Die Berechnung konvergiert. Die `Deviance` selbst kann als Transformation der Likelihood (vgl. Abschnitt 3.1.2) verstanden werden. Sie ist also ein Maß für die Passung des Modells zu den Daten, die von Iteration zu Iteration besser wird, bis ein willkürlicher Grenzwert für die Änderung (Default bei `tam.mml()`: $0.0001$) erreicht wurde.

- `Item Parameters`: Äquivalent zum Output `head(mod1PL$item_irt)`, s. u. bei der Erklärung der Kennwerte aus dem Objekt `mod1PL$item`.

- `Regression Coefficients`: Es wurden keine weiteren Hintergrundvariablen (z. B. Alter oder Gender) in das Modell eingefügt. Daher ist der Wert in diesem Fall $0$.

- `Variance`: Varianz des berechneten Parameters.

- `EAP Reliability`: **E**xpected-**A**-**P**osteriori-Reliabilität. Über ein statistisches Verfahren berechnetes Maß für die Reliabilität des Testinstruments. Kann in erster Näherung analog zu Cronbachs-$\alpha$ aus der klassischen Testtheorie interpretiert werden. Wichtiger Hinweis: Die EAP-Reliabilität ist ein zuverlässiger Schätzer für Populationen, nicht jedoch für Einzelpersonen!

Folgend wird das Dataframe-Objekt `mod1PL$item` aus dem Listen-Objekt `mod1PL` ausgewählt und mit der Funktion `head()` die ersten 6 von insgesamt 40 Einträgen ausgegeben. Es enthält verschiedene Spalten mit deskriptiven Kennwerten:


```r
head(mod1PL$item)
##    item    N      M  xsi.item AXsi_.Cat1 B.Cat1.Dim1
## I1   I1 2000 0.8270 -1.959017  -1.959017           1
## I2   I2 2000 0.8145 -1.857027  -1.857027           1
## I3   I3 2000 0.8000 -1.744435  -1.744435           1
## I4   I4 2000 0.7860 -1.640747  -1.640747           1
## I5   I5 2000 0.7725 -1.544800  -1.544800           1
## I6   I6 2000 0.7710 -1.534362  -1.534362           1
```
- `item`: Laufnummer der jeweiligen Items.

- `N`: Anzahl an Personen, die das jeweilige Item bearbeitet haben.

- `M`: Deskriptive Schwierigkeit des Items ($M = \frac{N_{korrekt}}{N_{gelöst}}$).

- `xsi.item`: *xsi* wird ausgesprochen wie geschrieben und bezieht sich auf den griechischen Buchstaben ($\xi$). Der $\xi$-Parameter ist die, mit dem Modell geschätzte, Aufgabenschwierigkeit auf der Skala von $-\infty$ bis $\infty$ mit 0 als Mittelwert. Übliche Werte in der Praxis liegen zwischen -3 bis 3. Eine Aufgabe mit Schwierigkeit $\xi=1$ ist dabei schwerer als eine Aufgabe mit Schwierigkeit $\xi=0$. Oft findet man den Schwierigkeitsparameter auch unter anderen griechischen Buchstaben in der Literatur, z. B. $\delta$ oder $\beta$. TAM übernimmt die Notation mit $\beta$ unter der Bezeichnung *IRT parametrization*. Siehe dazu die ersten 6 von 40 Einträgen im folgenden Dataframe-Objekt `mod1PL$item_irt`.


```r
head(mod1PL$item_irt)
##   item alpha      beta
## 1   I1     1 -1.959017
## 2   I2     1 -1.857027
## 3   I3     1 -1.744435
## 4   I4     1 -1.640747
## 5   I5     1 -1.544800
## 6   I6     1 -1.534362
```

- `AXsi_.Cat1`: Da im gezeigten Beispiel nur ein eindimensionales Modell ohne weitere Bedingungen berechnet wurde, entspricht der Wert dem $\xi$-Parameter, d. h. der Schwierigkeit. Unter anderen Bedingungen (beispielsweise Mehrdimensionalität, oder verschiedenen Testheftpositionen der Aufgabe), können verschiedende, bedingte Schwierigkeiten auftreten. Dazu ein fiktives, vereinfachtes Beispiel: Eine Aufgabe ist in zwei verschiedenen Testheften zu finden. In Testheft Nr. 1 ist sie immer die erste Aufgabe, in Testheft Nr. 2 ist sie immer die letzte Aufgabe. Die Testheftposition kann im statistischen Modell berücksichtigt werden und es würden dann zwei testheftabhängige Schwierigkeitsparameter berechnet, die sich als `AXsi_.Cat1` und `AXsi_.Cat2` im Output wiederfinden würden.

- `B.Cat1.Dim1`: Steigungsparameter. Im eindimensionalen 1PL-Modell wird der B-Parameter nicht berechnet, sondern auf $B=1$ fixiert. Oft findet man den Steigungsparameter auch unter der Bezeichnung $\alpha$ (siehe Output oben zu `xsi.item`).

Eine Zusammenfassung des Modellobjekts mit allen oben ausgeführten Kennwerten kann über den Befehl `summary(mod1PL)` erhalten werden.

### Deutung der Aufgabenschwierigkeiten
Die erhaltenen Schwierigkeitsparameter stehen unter dem Vorbehalt, dass das Rasch-Modell gültig ist [@Wu2016, 139ff.]. Sie setzen die Aufgaben nun jenseits von subjektiven Einflüssen miteinander in Beziehung. War eine Schwierigkeitseinschätzung a-priori (bspw. durch ein Expertenrating) noch von zahlreichen, personenabhängigen Einflüssen getragen, sind nun die Bearbeitungserfolge durch die Zielgruppe in der quantitativ-empirischen Erhebung integriert: Die Schwierigkeiten wurden gemessen und nicht über den Daumen gepeilt. Noch vor weiterführenden Analysen können die so erhaltenen, quantitativen Befunde wiederum durch qualitative Urteile abgeglichen werden: 

- Gibt es Aufgaben, die erwartungsgemäß schwerer/leichter waren als andere?
- Gibt es Aufgaben, deren Schwierigkeiten *nicht* erwartungskonform sind?
- War eine Aufgabe vielleicht zu einfach, weil die Distraktoren unpassend gewählt waren?
- ...

Die Aufgabenentwicklung führt so in einem Zusammenspiel aus objektiven Kriterien und subjektiver Synthese (bspw. Erfahrung von PraktikerInnen, Literaturrecherche, curriculare Anforderungen) zu validen und reliablen Testinstrumenten.

## Erzeugen einer Wright-Map
Mit einem Mathematiktest für GrundschülerInnen wird es kaum möglich sein, verschiedene Studierende der Mathematik und ihrer Fähigkeit zu rechnen zu unterscheiden. Analoges gilt für einen zu schweren Test für die GrundschülerInnen.

Für Leistungstests ist also eine breite Verteilung von Aufgabenschwierigkeiten über die Personenfähigkeiten wünschenswert. Wright-Maps erlauben eine Prüfung der Abdeckung, indem sie die Aufgabenschwierigkeiten und die Personenfähigkeiten grafisch miteinander in Beziehung setzen. Es wird dabei auf einen Blick deutlich, wenn in einem bestimmten Schwierigkeits-/Fähigkeitsintervall zu wenige oder zuviele Aufgaben vorliegen. Dies ist insbesondere in der Pilotierungsphase eines Tests hilfreich.

Das folgende Code-Beispiel schätzt die Personenfähigkeiten und schreibt sie über die Funktion `tam.wle` in das Objekt `thetas_1pl`. Außerdem werden die Aufgabenschwierigkeiten separat als Objekt `item_xsis_1pl` abgespeichert um anschließend mit der Funktion `wrightMap()` eine automatische Visualisierung zu erhalten (Abb. \@ref(fig:wright-map1)).


```r
thetas_1pl <- tam.wle(mod1PL)
item_xsis_1pl <- mod1PL$xsi$xsi

wrightMap(thetas_1pl$theta, item_xsis_1pl,
          main.title = "Beispiel für Wright-Map",
          axis.persons = "Fähigkeitsverteilung",
          axis.items = "Aufgaben")
```

<div class="figure">
<img src="c2_files/figure-html/wright-map1-1.png" alt="Eine Variante für eine Wright-Map." width="672" />
<p class="caption">(\#fig:wright-map1)Eine Variante für eine Wright-Map.</p>
</div>

Gut erkennbar ist die Fähigkeitsverteilung in Dimension 1 (schmaleres Panel links) und die numerische Zuordnung der Aufgaben zu dieser Dimension (breiteres Panel rechts). Ebenfalls deutlich wird die Äquivalenz von Personenfähigkeiten und Aufgabenschwierigkeiten, erkennbar an der Logit-Skala auf der rechten Seite.

Ungünstig ist die kategorische Aufgaben-Achse. Da der Datensatz 40 Aufgaben enthält, resultiert ein Overplot der Aufgaben-Namen, dem mit einer Alternativdarstellung begegnet werden kann (Abb. \@ref(fig:wright-map2)).


```r
wrightMap(thetas_1pl$theta, item_xsis_1pl, 
          item.side = itemClassic,
          main.title = "Beispiel für Wright-Map",
          axis.persons = "Fähigkeitsverteilung",
          axis.items = "Aufgabenverteilung")
```

<div class="figure">
<img src="c2_files/figure-html/wright-map2-1.png" alt="Eine Alternative Darstellung der Wright-Map." width="672" />
<p class="caption">(\#fig:wright-map2)Eine Alternative Darstellung der Wright-Map.</p>
</div>

In diesem Fall ist gut zu sehen, wie die Aufgaben - markiert durch ihren Laufindex aus dem Datensatz - von unten nach oben schwieriger werden. Außerdem erkennbar: Die Aufgaben sind näherungsweise uniform über das Schwierigkeits-/Fähigkeitsintervall verteilt. Außerdem stehen für sehr leistungsstarke und -schwache Personen (Ränder der Fähigkeitsverteilung) empirisch keine äquivalent schwierigen Aufgaben zur Verfügung. 

### Deutung der Wright-Maps
Wäre dieser Datensatz aus einer realen Studie entstanden, wäre die Nachkonstruktion von sehr schweren und sehr leichten Aufgaben zu empfehlen. Darüber hinaus halten sich im mittleren Fähigkeitsniveau die meisten Personen auf. Um zwischen diesen besser differenzieren zu können, wären auch dort mehr Aufgaben hilfreich.
