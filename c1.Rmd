---
title: "Untitled"

---

# Einführung
```{r setup, include=FALSE}
library("TAM")
```

## Rasch-Modellierung
Bei vielen Test geht es um die Frage, ob ein Probant eine bestimmt Fähigkeit besitzt und damit eine Aufgabe richtig lösen kann. Die Wahrscheinlichkeit, dass ein Proband eine Aufgabe aber richtig lösen kann, hängt sowohl von dessen Fähigkeit als auch von der Schwierigkeit der Aufgabe ab. Beide Punkte sind auf den ersten Blick nicht voneinander zu trennen. Die Rasch-Modellierung (benannt nach dem dänischen Statistiker Georg Rasch (1901–1980)) löst dieses Problem. Das Modell beschreibt wie wahrscheinlich es ist, dass ein Probandn $\nu$ ein Item i richtig löst in ab Abhängigkeit 

* eines individuellen Personenparameters für jeden Probanden $\xi_\nu$, welcher das Fähigkeitsausmaß des Probanden $\nu$ beschreibt und
* eines Aufgaben- oder Itemparameters $\sigma_i$, der ist den Schwierigkeitsgrad der Aufgabe i beschreibt. 

Die Modellannahmen lauten wie folgt:

* Das Maß der Fähigkeit jedes Probanden ist durch einen **einzigen** Parameter zu charakterisieren. Das heißt, dass es keine anderen Einflussfaktoren gibt und ein sog. eindimensionales Modell berechnet wird.

* Die Schwierigkeit der einzelnen Aufgaben ist ebenfalls durch einen einzigen Parameter charakterisiert; die Schwierigkeit stellt also ebenfalls ein eindimensionales Merkmal dar.

* Beide Parameter werden auf der selben Skala gemessen.

* Die Leistungen eines Probanden hängt über alle Aufgaben hinweg – abgesehen von Zufall –, einzig von der Fähigkeit des Probanden und der Schwierigkeit der Aufgabe ab, nicht aber davon, welche anderen Aufgaben sie bereits gelöst hat oder noch lösen wird. 

Zusammehhänge zwischen dem Personenparameter und der Schwierigkeit der Aufgabe kann man sich jetzt viele vorstellen. Der Zusammehang sollte aber auf jeden Fall so sein, dass die Wahrscheinlichkeit einer richtigen Antwort mit wachsender Fähigkeit steigt. Bei einem perfekten Item und idealen Probanden würde man hoffen, dass die Wahrscheinlichkeit einer richtigen Antwort für Probanden mit einer niedrigen Fähigkeit bei null liegt und ab einer bestimmten Fähigkeit sprunghaft auf eins ansteigt. Ganz so ideal wird es nicht sein und der Übergangsbereich wird etwas weicher verlaufen. Explizit wird angenommen, dass sich die Wahrscheinlichkeit einer richtigen Antwort einer logistischen Funktion folgend entwickelt. Man setzt für die Wahrscheinlichkeit einer richtigen Antwort unter der Bedingung einer Personenfähigkeit $\xi_\nu$ und Schwierigkeit der Aufgabe $\sigma_i$ an:

$$P(1|\xi_\nu, \sigma_i) = \frac{\exp(\xi_\nu - \sigma_i)}{1-\exp(\xi_\nu - \sigma_i)} $$
Die Lösungswahrscheinlichkeit für Aufgabe $i$ hängt also von Differenz von Personenfähigkeit und Aufgabengabenschwierigkeit ab. Formt man die Gleichung etwas um, kann man auch schreiben
$$\ln\left(\frac{P(1|\xi_\nu, \sigma_i)}{1 - P(1|\xi_\nu, \sigma_i)}\right) = \ln\left(\frac{P(1|\xi_\nu, \sigma_i)}{ P(0|\xi_\nu, \sigma_i)}\right) = \xi_\nu - \sigma_i$$
Der natürliche Logarithmus der Chance (Wahrscheinlichkeit der richtigen Lösun geteilt durch Wahrscheinlichkeit der falschen Lösung) gleich der Differenz von Personenfähigkeit und Aufgabengabenschwierigkeit. Plottet man Chance gegen diese Differenz erhält man eine Gerade mit Steigung 1.

Diese Steigung und damit die Steigung des Übergangs von $P$ wird für das Rasch-Modell also als fest angenommen. Die Steigung wird auch als Trennschärfe bezeichnet, weil Sie eine Aussage darüber liefert, wie klar ein Item zwischen den Fähigkeiten zweiter Probanden dicht an der Schwierigkeit des Items trennen kann. Idealisiert würde ein perfektes Item von einer Person mit einer Fähigkeit $\xi_\nu$ nie gelöst werden, während ein Person mit einer leicht höheren Fähigkeit das Item immer löst. Bei höheren Modellen wie dem 2-PL geht die Steigung als zusätzlicher Parameter ein.

### Wie wird der beste Fit gefunden?
Der beste Fit zwischen Modell und Daten, also der Satz von $\xi_\nu$ und $\sigma_i$, der die beste Passung zwischen Modell und Daten lieft, kann über verschiedene Verfahren wie unter anderem das Least-quares- oder aber das Maximum-Likelyhood-Verfahrung gefunden werden. Bei letzterem wird durch ein iteratives Vorgehen, die sog. Likelyhood Funktion
$$ L= \prod\limits_{\nu,i}P(1|\xi_\nu, \sigma_i)$$
berechnet, welche genau dann maximal wird, wenn die Wahrscheinlichkeit genau die gemessene Stichprobe zu erhalten maximal wird.

### zum Weiterschauen
Sehr interessante Videos zu diesem Thema, die das Ganze noch einmal wesentlich umfangreicher beschreiben, sind:

* [A Conceptual Introduction to Item Response Theory](https://www.youtube.com/watch?v=SrdbllMYq8M&list=PLJNUIJnElUzDmrIPunMyF3tTvIHb65wNb)
* [Logistic Regression](https://www.youtube.com/watch?v=yIYKR4sgzI8&list=PLblh5JKOoLUKxzEP5HA2d-Li7IJkHfXSe)

## Der Datensatz
Der für diese Erklärung verwendete Datensatz stammt aus dem Paket TAM und hat das Format einer einfachen Matrix. Es handelt sich um simulierte Daten von 2000 Probanden (als Zeilen) zu jeweils 40 Items (als Spalten). Die Spalten für die einzelnen Items sind mit I1 bis I40 bezeichnet. Eine Spalte für eine Probanden ID oder ähnliches gibt es nicht. Auch hat der Datensatz keine fehlenden Daten, d.h. zu jedem Probanden gibt es Daten zu jedem Item. Die Items selbst sind alle dichotom (richtig/falsch) und mit 1 und 0 codiert. 

```{r data}
data(data.sim.rasch)
head(data.sim.rasch)
```
